# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
# SPDX-FileCopyrightText: All rights reserved.
# SPDX-License-Identifier: Apache-2.0
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

hydra:
  #output_subdir: ./hrrr/
  job:
    chdir: True
  run:
    dir: /hrrr_out/
    #dir: /coreai_climate_earth2/corrdiff/training_output/
  output_subdir: null

outdir: "./output_regression_hrrr_test"

## Hyperparameters
duration: 200
  # Training duration
batch_size_global: 256
  # Total batch size
batch_size_gpu: 1
  # Limit batch size per GPU
cbase: null  # TODO check
  # Channel multiplier
cres: 1  # TODO check
  # Channels per resolution
lr: 0.0002
  # Learning rate
ema: 0.5
  # EMA half-life
dropout: 0.13
  # Dropout probability
augment: 0.0
  # Augment probability

hr_mean_conditioning: False
  # High-res mean (regression's output) as additional condition
gridtype: "sinusoidal" #"test"
  # can be either linear, sinusoidal, or learnable
N_grid_channels: 4 
  # for pos embedding
grad_clip_threshold: false
  # no gradient clipping for defualt non-patch-based training
lr_decay: 1

P_mean: -1.2
P_std: 1.2
sigma_data: 0.5

## Performance options
fp_optimizations: fp32
 #amp-bf16
  # Floating point mode, one of ["fp32", "fp16", "amp-fp16", "amp-bf16"]
  # "amp-{fp16,bf16}" activates Automatic Mixed Precision (AMP) with {float16,bfloat16}
ls: 1
  # Loss scaling
bench: false
  # Enable cuDNN benchmarking
workers: 4
  # DataLoader worker processes
songunet_checkpoint_level: 1 # 0 means no checkpointing
  # Gradient checkpointing level, value is number of layers to checkpoint

## I/O-related options
checkpoint_dir: checkpoints
  # Where to save the checkpoints
wandb_mode: disabled
  # Wights & biases mode [online, ofline, disabled]
tick: 1
  # How often to print progress
dump: 50 #500
  # How often to dump state
seed: null  # TODO check
  # Random seed
transfer: null  # TODO check
  # Transfer learning from network pickle
dry-run: false
  # Print training options and exit
use_tf32: true
## Weather data options
dataset:
  type: "hrrr"
  data_path: "/datasets/hrrr/downscaling/"
  ds_factor: 4
  train: True
  train_years: [2017, 2018, 2019, 2020, 2021]
  valid_years: [2022]
  hrrr_window: [[1,1057], [4,1796]] # need dims to be divisible by 16 [[0,1024], [0,1024]]
  sample_shape: null #[1024, 1024] # 1024,1024 w/ 1 batch 4 hrrr channels and all era5 channels is 77gb
  #exclude_channels: ["gust","2d", "2r", "tp", "cape", "cin", "tcc", "dswrf", "dlwrf", "vbdsf", "veril", "hpbl"]
  # avail
  # ['2t', '10u', '10v', 'refc', 'gust', '2d', '2r', 'tp', 'cape', 'cin', 'tcc', 'dswrf', 'dlwrf', 'vbdsf', 'veril', 'hpbl']
  # 2022 doesn't have the full set of variables
  # only ['10u', '10v', '2t', 'tp', 'refc'], tp possibly bad
  #hrrr_channels: ["refc", "2t", "10u", "10v"]
  out_channels: ["refc", "2t", "10u", "10v"]
  # ['u10m', 'v10m', 't2m', 'tcwv', 'sp', 'msl', 'u1000', 'u850', 'u500', 'u250', 'v1000', 'v850', 'v500', 'v250', 'z1000', 'z850', 'z500', 'z250', 't1000', 't850', 't500', 't250', 'q1000', 'q850', 'q500', 'q250']
  #era5_channels:  ["u500", "v500", "z500", "t500", "u850", "v850", "z850", "t850", "u10m", "v10m", "t2m", "tcwv"]
  in_channels:  ["u500", "v500", "z500", "t500", "u850", "v850", "z850", "t850", "u10m", "v10m", "t2m", "tcwv"]
