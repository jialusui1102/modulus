# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
# SPDX-FileCopyrightText: All rights reserved.
# SPDX-License-Identifier: Apache-2.0
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.


## Hyperparameters
duration: 200
  # Training duration
batch_size_global: 256
  # Total batch size
batch_size_gpu: 2
  # Limit batch size per GPU
cbase: null  # TODO check
  # Channel multiplier
cres: 1  # TODO check
  # Channels per resolution
lr: 0.0002
  # Learning rate
ema: 0.5
  # EMA half-life
dropout: 0.13
  # Dropout probability
augment: 0.0
  # Augment probability
hr_mean_conditioning: False
  # High-res mean (regression's output) as additional condition
gridtype: "sinusoidal"
  # can be either linear, sinusoidal, or learnable
N_grid_channels: 4
grad_clip_threshold: false
  # no gradient clipping for defualt non-patch-based training
lr_decay: 1

## Performance options
fp_optimizations: amp-bf16
  # Floating point mode, one of ["fp32", "fp16", "amp-fp16", "amp-bf16"]
  # "amp-{fp16,bf16}" activates Automatic Mixed Precision (AMP) with {float16,bfloat16}
ls: 1
  # Loss scaling
bench: false
  # Enable cuDNN benchmarking
workers: 4
  # DataLoader worker processes
songunet_checkpoint_level: 0 # 0 means no checkpointing
  # Gradient checkpointing level, value is number of layers to checkpoint


## I/O-related options
checkpoint_dir: checkpoints
  # Where to save the checkpoints
tick: 1
  # How often to print progress
dump: 500
  # How often to dump state
seed: null  # TODO check
  # Random seed
transfer: null  # TODO check
  # Transfer learning from network pickle
dry-run: false
  # Print training options and exit
validation_dump: 50
  # how often to record the validation loss
validation_steps: 10
  # how many loss evaluations are used to compute the validation loss per checkpoint
wandb_mode: online
  # Weights & biases mode [online, ofline, disabled]
wandb_project:  "Modulus-Generative"
 # Weights & biases project
wandb_entity: "CorrDiff"
 # Weights & biases entity (i.e. a workspace, personal or a team workspace)

## Weather data options
dataset:
  type: "hrrr"
  data_path: "/us_data/downscaling"
  ds_factor: 4
  train: true
  train_years: [2017, 2018, 2019, 2020, 2021]
  valid_years: [2022]
  hrrr_window: [[1,1057], [4,1796]] # need dims to be divisible by 16
  sample_shape: null  # 1024,1024 w/ 1 batch 4 hrrr channels and all era5 channels is 77gb
  # avail
  # ['2t', '10u', '10v', 'refc', 'gust', '2d', '2r', 'tp', 'cape', 'cin', 'tcc', 'dswrf', 'dlwrf', 'vbdsf', 'veril', 'hpbl']
  # 2022 doesn't have the full set of variables
  # only ['10u', '10v', '2t', 'tp', 'refc'], tp has NaNs, should be 0?
  out_channels: ["refc", "2t", "10u", "10v"]
  # avail 
  # ['u10m', 'v10m', 't2m', 'tcwv', 'sp', 'msl', 'u1000', 'u850', 'u500', 'u250', 'v1000', 'v850', 'v500', 'v250', 'z1000', 'z850', 'z500', 'z250', 't1000', 't850', 't500', 't250', 'q1000', 'q850', 'q500', 'q250']
  in_channels: ["u500", "v500", "z500", "t500", "u850", "v850", "z850", "t850", "u10m", "v10m", "t2m", "tcwv"]
  # in_channels: ['u10m', 'v10m', 't2m', 'tcwv', 'sp', 'msl', 'u1000', 'u850', 'u500', 'u250', 'v1000', 'v850', 'v500', 'v250', 'z1000', 'z850', 'z500', 'z250', 't1000', 't850', 't500', 't250', 'q1000', 'q850', 'q500', 'q250']
  train_test_split: true
  overfit: False
  use_all: True

# Validation dataset options
# (need to set dataset.train_test_split == true to have an effect)
validation_dataset:
  train: true
  use_all: True
